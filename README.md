## Basics

#### Implementing easy ML the hard way

The point of this project is more academic than practical - I want to give myself a refresher in 
building stuff from scratch, starting with a perceptron model, then getting into convolutional nets
and hopefully transformers. Ideally transformers will happen more slowly, because I would like to 
have a job before I get that far, but who knows. I'm using this to learn Rust as well, thus implementing
computation-heavy functions in Rust and then calling them from python (instead of using np.linalg)

### Development roadmap

- Linear algebra basics
- Regression (MLR, maybe Lasso or Ridge)
- Utilites (loss functions, train-test split)
- Perceptron (basic, multi-layer)
- Support vector machine
- Convolutional net, demo with MNIST digits

### Installation

TBD


### Contribution

TBD



